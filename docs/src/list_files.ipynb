{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(how-to-list_files)=\n",
    "# List dat files \n",
    "ApRES data is stored in binary files with the extension `.dat`. \n",
    "One of the main purposes of xapres is to load these files into a format that is easy to work with in python, xarray datasets. \n",
    "\n",
    "A class called `from_dats` is included in the `xapres.load` module to handle loading .dat files. \n",
    "\n",
    "First we load the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../xapres\") \n",
    "import xapres as xa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `from_dats` object is initialized with one option parameter `loglevel`, which can be set to `\"DEBUG\"` to print out more information about the processing, or ignored to suppress this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = xa.load.from_dats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The method `list_files` lists all the dat files in a given directory or cloud-based file-like location. It searches recursively through the file structure beneath the directory you supply to it and produces a list of all files it finds with the extension `.dat` or `.DAT`. \n",
    "\n",
    "This method can be useful for looking at what and how many files you are dealing with and it is used internally by other methods when loading and concatenating data to produce an xarray dataset. \n",
    "\n",
    "## Local files\n",
    "\n",
    "If you have dat files in your current directory, you can simply run `filepaths = fd.list_files()` to produce a list of the dat files.\n",
    "\n",
    "Or to find the dat files in a specific local directory, you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/thwaites/DATA2023-02-12-0437.DAT']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = fd.list_files(directory = '../data/')\n",
    "filepaths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 1 dat file in the directory `../data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote files\n",
    "We can also load dat file stored in google cloud storage (i.e. a google bucket)\n",
    "\n",
    "```{note}\n",
    "We will add the capability to use AWS S3 storage in the future.\n",
    "```\n",
    "\n",
    "To load from a google bucket you must provide the path (specifically the 'gsutil URI' of the directory). to the bucket as the first argument `directory`. The following cell produces a list of all the dat files in the google bucket and prints out the first five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://ldeo-glaciology/apres/thwaites/continuous/ApRES_LTG/SD1/DIR2000-01-04-2210/DATA2000-01-04-2210.DAT',\n",
       " 'gs://ldeo-glaciology/apres/thwaites/continuous/ApRES_LTG/SD1/DIR2000-01-04-2221/DATA2000-01-04-2221.DAT',\n",
       " 'gs://ldeo-glaciology/apres/thwaites/continuous/ApRES_LTG/SD1/DIR2023-01-15-2304/DATA2023-01-15-2304.DAT',\n",
       " 'gs://ldeo-glaciology/apres/thwaites/continuous/ApRES_LTG/SD1/DIR2023-01-15-2330/DATA2023-01-15-2330.DAT',\n",
       " 'gs://ldeo-glaciology/apres/thwaites/continuous/ApRES_LTG/SD1/DIR2023-01-16-0051/DATA2023-01-16-0051.DAT']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = fd.list_files(directory='gs://ldeo-glaciology/apres/thwaites/continuous/ApRES_LTG')\n",
    "filepaths[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search suffix\n",
    "`list_files` also takes an optional argument `suffix` which can be used to search for files with a specific suffix. This can be useful when the .dat files have been collected as part of a polarimetric radar survey, where the antennas are rotated to different orientations for each measurement. The user typically names the dat files with HH, HV, VH, or VV to signify the orientation of the antennas used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We found 186 files in gs://ldeo-glaciology/apres/thwaites/2022-2023/Polarmetric; only 45 had an HV suffix\n"
     ]
    }
   ],
   "source": [
    "directory = \"gs://ldeo-glaciology/apres/thwaites/2022-2023/Polarmetric\"\n",
    "all_polarimetric_files = fd.list_files(directory=directory)\n",
    "just_HV_files = fd.list_files(directory=directory, search_suffix='HV')\n",
    "print(\"\")\n",
    "print(f\"We found {len(all_polarimetric_files)} files in {directory}; only {len(just_HV_files)} had an HV suffix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Loading .dat files is dealt with using a `from_dats` object in the `xapres.load` module. The `list_files` method can be used to list all the dat files in a local directory or a google bucket. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-book-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
