{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66083e72-16ca-4fc0-aebc-2e0ec36ebbe6",
   "metadata": {},
   "source": [
    "# Tests to be implemented in github actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe65d4f-0fc5-4774-b034-b9c81fb5b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import sys\n",
    "sys.path.append(\"../../../xapres/\")\n",
    "import xapres as xa\n",
    "import numpy\n",
    "from xapres import load, utils\n",
    "from numpy import allclose as npc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6744fd5-b286-4f08-b14b-165786bab26d",
   "metadata": {},
   "source": [
    "## Test of file name/number selection in xapres.load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838b9e9b-6681-4b89-a375-c00bd496dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that we can select and load the same file using two different methods: 1) selecting the file number, \n",
    "# and 2) using the filename that we get from 1) to load the same file again.\n",
    "def test_file_selection():\n",
    "    directory='gs://ldeo-glaciology/GL_apres_2022/A101'\n",
    "    fs1 = load.from_dats()\n",
    "    fs1.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_numbers_to_process=[0,1])\n",
    "\n",
    "    fs2 = load.from_dats()\n",
    "    fs2.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_names_to_process = fs1.dat_filenames_to_process)\n",
    "\n",
    "    assert fs1.data.identical(fs2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8d5d35-7eb6-48ca-ad4c-5cee64fe7e96",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_file_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mtest_file_selection\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m fs1\u001b[38;5;241m.\u001b[39mload_all(directory, \n\u001b[1;32m      7\u001b[0m             remote_load \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m             file_numbers_to_process\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m fs2 \u001b[38;5;241m=\u001b[39m load\u001b[38;5;241m.\u001b[39mfrom_dats()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mfs2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremote_load\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_names_to_process\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfs1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdat_filenames_to_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m fs1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39midentical(fs2\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Documents/science/ApRES/xapres/notebooks/test_notes/../../../xapres/xapres/load.py:261\u001b[0m, in \u001b[0;36mfrom_dats.load_all\u001b[0;34m(self, directory, remote_load, file_numbers_to_process, file_names_to_process, bursts_to_process, attended, polarmetric, legacy_fft, corrected_pad, max_range, addProfileToDs_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dat_filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdat_filenames_to_process:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad dat file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdat_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     dat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dat_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_load\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     multiBurstxarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_bursts_in_dat_to_xarray(dat, bursts_to_process)\n\u001b[1;32m    265\u001b[0m     list_of_multiBurstxarrays\u001b[38;5;241m.\u001b[39mappend(multiBurstxarray)\n",
      "File \u001b[0;32m~/Documents/science/ApRES/xapres/notebooks/test_notes/../../../xapres/xapres/load.py:117\u001b[0m, in \u001b[0;36mfrom_dats.load_dat_file\u001b[0;34m(self, dat_filename, remote_load)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dat_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, dat_filename, remote_load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DataFileObject, given a filename.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFileObject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_load\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/science/ApRES/xapres/notebooks/test_notes/../../../xapres/xapres/load.py:783\u001b[0m, in \u001b[0;36mDataFileObject.__init__\u001b[0;34m(self, Filename, remote_load)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m    780\u001b[0m     datafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m inbuff \u001b[38;5;241m=\u001b[39m \u001b[43mdatafile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m datafile\u001b[38;5;241m.\u001b[39mclose()     \n\u001b[1;32m    786\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Burst Header ***\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/site-packages/fsspec/spec.py:1941\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1939\u001b[0m     \u001b[38;5;66;03m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1941\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m read: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39m_log_stats(),\n\u001b[1;32m   1949\u001b[0m )\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/site-packages/fsspec/caching.py:234\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    232\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, end \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_requested_bytes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# new block replaces old\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m=\u001b[39m start\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache)\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/site-packages/gcsfs/core.py:1924\u001b[0m, in \u001b[0;36mGCSFile._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get data from GCS\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \n\u001b[1;32m   1920\u001b[0m \u001b[38;5;124;03mstart, end : None or integers\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;124;03m    if not both None, fetch only given range\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcsfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot satisfiable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/site-packages/fsspec/asyn.py:91\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# this loops allows thread to get interrupted\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/xapres/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_file_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3900b4-014b-4247-846c-9e9aa40be34c",
   "metadata": {},
   "source": [
    "## Test the loading of a single dat file from the google bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a583911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytest\n",
    "#from xapres import ApRESDefs\n",
    "\n",
    "def test_dat_file_loading():\n",
    "    directory='gs://ldeo-glaciology/GL_apres_2022/A101'\n",
    "    fs = load.from_dats(max_range=1400)\n",
    "    fs.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_numbers_to_process=[0],\n",
    "                bursts_to_process=[0])\n",
    "    assert numpy.isclose(fs.data.chirp.mean().values, 0.02611298) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8831b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat_file_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395cbf35-cb24-4a15-ab5b-0082cedefc3d",
   "metadata": {},
   "source": [
    "## Test the file search code\n",
    "Make sure that the 'dat' is not case sensitive and that the search suffix option works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03eb4eee-ed0c-497c-9b4e-d2b287506139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_file_search_methods():\n",
    "    fs = load.from_dats()   \n",
    "    data_directory = 'data'\n",
    "    \n",
    "    higher_level_list_of_dats = fs.list_files(data_directory + \"/sample\")\n",
    "    \n",
    "    # this checks that the list of files is not empty\n",
    "    assert higher_level_list_of_dats  \n",
    "\n",
    "    lower_level_list_of_dats = fs.list_files(data_directory + \"/sample/polarmetric\")\n",
    "    # test that all the files found in a lower level directory were also found when searching in a higher level directory\n",
    "    assert all(item in higher_level_list_of_dats for item in lower_level_list_of_dats)\n",
    "\n",
    "    # test that the case of the extension (DAT vs dat) doesnt matter\n",
    "    assert len(fs.list_files(data_directory + \"/sample/different_case_examples\")) == 2\n",
    "\n",
    "    # test the search_suffix option is working\n",
    "    assert len(fs.list_files(data_directory + \"/sample/polarmetric\", search_suffix='HH')) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eece7a5-5f4e-478a-9ccf-693a2699aceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_file_search_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m, in \u001b[0;36mtest_file_search_methods\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m higher_level_list_of_dats \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mlist_files(data_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# this checks that the list of files is not empty\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m higher_level_list_of_dats  \n\u001b[1;32m     10\u001b[0m lower_level_list_of_dats \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mlist_files(data_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sample/polarmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# test that all the files found in a lower level directory were also found when searching in a higher level directory\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_file_search_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa893575-d8ed-4d3a-9740-e16a51e6865c",
   "metadata": {},
   "source": [
    "## Test file selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "091b6e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "076ae5d4-5471-4945-b2e5-d1932d46b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use two different methods for selecting the same ApRES DAT file from a google bucket. \n",
    "#  In each case load it and then check that we have loaded the correct file. \n",
    "\n",
    "def test_file_selection_methods():\n",
    "    directory='../../data/sample/polarmetric'\n",
    "    fs1 = load.from_dats()\n",
    "    fs1.load_all(directory, legacy_fft=False, file_numbers_to_process=[0,1])\n",
    "\n",
    "    fs2 = load.from_dats()\n",
    "    fs2.load_all(directory, legacy_fft=False, file_names_to_process = fs1.dat_filenames_to_process)\n",
    "\n",
    "    assert fs1.data.equals(fs2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ced97345-a02e-4bbb-a428-1bcb9eb74d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_selection_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d8dc1-9f2f-4ecd-8aa0-7a92586cf847",
   "metadata": {},
   "source": [
    "## Test polarmetric loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf06f517-d30a-4886-833e-aeec40104a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test polarmetric local loading by loading the same waypoint twice as if it is two different ones and checking \n",
    "# that you get the same thing twice.\n",
    "\n",
    "# tests the attended option and the polarmetric option from locally stored dat files (as opposed to cloud stored dat files)\n",
    "\n",
    "def test_polarmetric_load():\n",
    "    \n",
    "    fs = load.from_dats()\n",
    "    fs.load_all(attended=True, \n",
    "                directory=[\"../../data/sample/polarmetric\", \"../../data/sample/polarmetric\"], \n",
    "                polarmetric=True)\n",
    "    \n",
    "    assert len(fs.data.waypoint) == 2\n",
    "    assert all(fs.data.isel(waypoint=0).filename.values == fs.data.isel(waypoint=1).filename.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8a5486-c837-4ab4-ac41-20af366571e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polarmetric_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e835d-ae9d-47a9-b9fc-f8ee196d1be8",
   "metadata": {},
   "source": [
    "## Test `generate_xarray` and `load_zarr` wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00fd03b0-b277-4df1-99b3-21c6047ee6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test `generate_xarray` and `load_zarr` wrappers\n",
    "def test_wrappers():\n",
    "    \n",
    "    from_DAT_unattended = load.generate_xarray(directory='data/sample/single_dat_file/', \n",
    "                file_numbers_to_process = [0], \n",
    "                bursts_to_process=[0],\n",
    "                )\n",
    "\n",
    "    from_zarr = load.load_zarr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "066b4011-15d0-4945-b40c-2cf79f943f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wrappers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a390ba7-5893-4fd7-9414-d1107f2acd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the displacement calculation\n",
    "\n",
    "def test_displacement_calculation():\n",
    "    fd = xa.load.from_dats()\n",
    "\n",
    "    from_local = fd.load_all(directory='../../data/sample/multi-burst-dat-file/', legacy_fft=False) # load the data from a local directory\n",
    "    p1 = from_local.isel(time=2, attenuator_setting_pair=0).profile # select a profile \n",
    "    p2 = from_local.isel(time=5, attenuator_setting_pair=0).profile # select a different profile \n",
    "\n",
    "    utils.compute_displacement(p1, p2, bin_size = 25)    # calculate the displacement between the two profiles. Use a non-default value for bin_size\n",
    "\n",
    "\n",
    "    profiles = from_local.isel(attenuator_setting_pair=0).profile  # select all the profiles on a specfic date\n",
    "    results = profiles.displacement_timeseries(bin_size = 30, offset = 3) # compute a time series of displacement from these data. Use non-default values for offset and bin_size. \n",
    "    assert results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524b2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_displacement_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfeb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fft_calculations():\n",
    "# initialize\n",
    "    fd = xa.load.from_dats()\n",
    "    directory='../../data/sample/single_dat_file/'\n",
    "\n",
    "    # load the data from dat files\n",
    "    ## load data from a local directory, compute the fft with the legacy method and dont correct the padding error\n",
    "    load_oldfft_uncorrectedPad = fd.load_all(directory, legacy_fft=True, corrected_pad=False).profile\n",
    "    ## load data from a local directory, compute the fft with the legacy method, but this time correct the padding error\n",
    "    load_oldfft_correctedPad = fd.load_all(directory, legacy_fft=True, corrected_pad=True).profile\n",
    "\n",
    "    ## define some options for the new fft to use the older defaults, i.e. before we corrected things to agree eactly with fmcw_load (https://github.com/ldeo-glaciology/xapres/pull/62)\n",
    "    ops = {'demean': False, 'scale_for_window': False}\n",
    "\n",
    "    ## load from a local directory, compute the fft with the new method\n",
    "    load_newfft_full = fd.load_all(directory, legacy_fft=False, addProfileToDs_kwargs=ops)\n",
    "    load_newfft = load_newfft_full.profile\n",
    "    ## load from a local directory, compute the fft with the new method while  setting the crop-limits on the chirp to be their default values (this shouldnt effect the answer from the line above)\n",
    "    load_newfft_defaultLimits = fd.load_all(directory, legacy_fft=False, addProfileToDs_kwargs={'crop_chirp_start': 0,'crop_chirp_end': 1} | ops).profile\n",
    "    ## load from a local directory, compute the fft with the new method while  setting the crop-limits on the chirp to some other values (this will effect the answer)\n",
    "    load_newfft_nonDefaultLimits = fd.load_all(directory, legacy_fft=False, addProfileToDs_kwargs={'crop_chirp_start': 0,'crop_chirp_end': 0.5} | ops).profile\n",
    "\n",
    "    # Compute the ffts on pre-loaded data\n",
    "    ## use the method .addProfileToDs() to compute the fft on a pre-loaded dataset\n",
    "    afterLoad_newfft_ds  = load_newfft_full.addProfileToDs(**ops)\n",
    "    ## use the method .computeProfile() to compute the fft on a pre-loaded chirp dataarray\n",
    "    afterLoad_newfft_da  = load_newfft_full.chirp.computeProfile(**ops)\n",
    "\n",
    "    # Change a constant used in the calculation of the range, this dosesnt effect the profiles, just the profile_range\n",
    "    constants = load_newfft_full.attrs['constants']\n",
    "    constants['c'] = 2e8\n",
    "    afterLoad_newfft_da_differentConstants = load_newfft_full.chirp.computeProfile(constants=constants, **ops)\n",
    "\n",
    "    assert not npc(load_oldfft_uncorrectedPad.values, load_oldfft_correctedPad.values)\n",
    "    d = load_newfft.dims  #needed to transpose the dataarrays that use legacy_fft=True to be the same as those which use legacy_fft=False\n",
    "    assert npc(load_oldfft_correctedPad.transpose(*d).values, load_newfft.values)\n",
    "    assert npc(load_oldfft_correctedPad.transpose(*d).values, load_newfft_defaultLimits.values)\n",
    "    assert npc(afterLoad_newfft_ds.profile.values, load_newfft_full.profile.values)\n",
    "    assert npc(afterLoad_newfft_da.values, load_newfft_full.profile.values)\n",
    "    assert npc(afterLoad_newfft_da_differentConstants.values, load_newfft_full.profile.values)\n",
    "    assert not npc(afterLoad_newfft_da_differentConstants.profile_range.values, load_newfft_full.profile_range.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a8401a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fft_calculations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c91b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "def test_bound_methods_are_added_correctly():\n",
    "    assert xr.DataArray.dB\n",
    "    assert xr.DataArray.sonify\n",
    "    assert xr.DataArray.displacement_timeseries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7de01d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bound_methods_are_added_correctly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cef6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../../../xapres/\")\n",
    "import xapres as xa\n",
    "\n",
    "def test_comparison_with_matlab_code():\n",
    "    \"\"\" Test that we get the same results as apres data loaded using fmcw_load, \n",
    "    a script typically used to load apres data:\n",
    "\n",
    "    ApRES data is traditionally processed with code written in matlab supplied by bas (fmcw_plot, etc., https://github.com/ldeo-glaciology/phase-sensitive-radar-processing/tree/main/code/ApRES_Utils_Nicholls_250221). \n",
    "\n",
    "    Here we compare the results of running xpares and the results of running scripts from this collection of matlab code. \n",
    "\n",
    "    \"\"\"\n",
    "    # load the chirps, perform an fft, and put them all in an xarray\n",
    "    directory = '../../data/sample/thwaites/'\n",
    "    p_data = xa.load.generate_xarray(directory=directory, addProfileToDs_kwargs={'max_range': 2500})\n",
    "    p_chirps = p_data['chirp']\n",
    "\n",
    "    \"\"\"\n",
    "    Load output of matlab code\n",
    "    The mat file loaded below was created using this version of the fmcw code: https://github.com/ldeo-glaciology/phase-sensitive-radar-processing/tree/main/code/ApRES_Utils_Nicholls_250221\n",
    "    and these commands\n",
    "    ```\n",
    "    vdat = fmcw_load('../../data/sample/thwaites/DATA2023-02-12-0437.DAT'); %defaults to just the first burst\n",
    "    [rc,~,spec_cor,spec] = fmcw_range(vdat, 2, 2500, @blackman);\n",
    "    save('../data/sample/thwaites/DATA2023-02-12-0437_p4.mat')\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # import mat file from the data directory\n",
    "    import scipy.io as sio\n",
    "    m_data = sio.loadmat('../../data/sample/thwaites/DATA2023-02-12-0437_p2.mat')\n",
    "\n",
    "    m_profiles = m_data['spec_cor']\n",
    "\n",
    "    vdat = m_data['vdat']\n",
    "\n",
    "    m_chirps = vdat[0,0]['vif']\n",
    "    m_chirp = m_chirps[0,]\n",
    "\n",
    "    # extract just one chirp fro the xapres-loaded data\n",
    "    p_chirp = p_chirps.isel(time=0, chirp_num=0).values.squeeze()\n",
    "\n",
    "    # ensure that they are the same except for a 1.25 offset (which is not important)\n",
    "    assert npc(m_chirp, p_chirp[:len(m_chirp)] + 1.25)\n",
    "\n",
    "    # compute profiles using the same constants that are generated by the matlab code to get an exact comparison\n",
    "    ## define a constants dict\n",
    "    constants = {}\n",
    "    constants['T'] = 1               # chirp duration [s]\n",
    "    constants['f_1'] = 200e6         # starting frequency [Hz]\n",
    "    constants['f_2'] = 400e6         # ending frequency [Hz]\n",
    "    constants['B'] = vdat[0][0]['B'][0][0]         # bandwidth [Hz]\n",
    "    constants['K'] = vdat[0][0]['K'][0][0]/2/np.pi            # rate of chnge of frequency [Hz/s]\n",
    "    constants['c'] = 300000000.0     # speed of light in a vacuum [m/s]\n",
    "    constants['ep'] = 3.18           # permittivity of ice\n",
    "    constants['f_c'] = vdat[0][0]['fc'][0][0]# center frequency [Hz]\n",
    "    constants['dt'] = 1/40000        # time step [s]\n",
    "\n",
    "    # compute the profiles using these constants\n",
    "    temp_new_constants = p_data.chirp.isel().computeProfile(constants=constants, max_range = 2500).isel(time=0).values.squeeze() \n",
    "   \n",
    "    # compare all the profiles to the atlab-loaded ones.\n",
    "    assert np.allclose(m_profiles, temp_new_constants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c299c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "test_comparison_with_matlab_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348631ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xapres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
