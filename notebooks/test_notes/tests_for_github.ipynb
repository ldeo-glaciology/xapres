{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66083e72-16ca-4fc0-aebc-2e0ec36ebbe6",
   "metadata": {},
   "source": [
    "# Tests to be implemented in github actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe65d4f-0fc5-4774-b034-b9c81fb5b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../xapres/\")\n",
    "import xapres as xa\n",
    "import numpy\n",
    "from xapres import load, utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6744fd5-b286-4f08-b14b-165786bab26d",
   "metadata": {},
   "source": [
    "## Test of file name/number selection in xapres.load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838b9e9b-6681-4b89-a375-c00bd496dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that we can select and load the same file using two different methods: 1) selecting the file number, \n",
    "# and 2) using the filename that we get from 1) to load the same file again.\n",
    "def test_file_selection():\n",
    "    directory='gs://ldeo-glaciology/GL_apres_2022/A101'\n",
    "    fs1 = load.from_dats(max_range=1400)\n",
    "    fs1.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_numbers_to_process=[0,1])\n",
    "\n",
    "    fs2 = load.from_dats(max_range=1400)\n",
    "    fs2.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_names_to_process = fs1.dat_filenames_to_process)\n",
    "\n",
    "    assert fs1.data.identical(fs2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8d5d35-7eb6-48ca-ad4c-5cee64fe7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3900b4-014b-4247-846c-9e9aa40be34c",
   "metadata": {},
   "source": [
    "## Test the loading of a single dat file from the google bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a583911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytest\n",
    "#from xapres import ApRESDefs\n",
    "\n",
    "def test_dat_file_loading():\n",
    "    directory='gs://ldeo-glaciology/GL_apres_2022/A101'\n",
    "    fs = load.from_dats(max_range=1400)\n",
    "    fs.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_numbers_to_process=[0],\n",
    "                bursts_to_process=[0])\n",
    "    assert numpy.isclose(fs.data.chirp.mean().values, 0.02611298) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8831b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat_file_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395cbf35-cb24-4a15-ab5b-0082cedefc3d",
   "metadata": {},
   "source": [
    "## Test the file search code\n",
    "Make sure that the 'dat' is not case sensitive and that the search suffix option works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03eb4eee-ed0c-497c-9b4e-d2b287506139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_file_search_methods():\n",
    "    fs = load.from_dats()   \n",
    "    data_directory = 'data'\n",
    "    \n",
    "    higher_level_list_of_dats = fs.list_files(data_directory + \"/sample\")\n",
    "    \n",
    "    # this checks that the list of files is not empty\n",
    "    assert higher_level_list_of_dats  \n",
    "\n",
    "    lower_level_list_of_dats = fs.list_files(data_directory + \"/sample/polarmetric\")\n",
    "    # test that all the files found in a lower level directory were also found when searching in a higher level directory\n",
    "    assert all(item in higher_level_list_of_dats for item in lower_level_list_of_dats)\n",
    "\n",
    "    # test that the case of the extension (DAT vs dat) doesnt matter\n",
    "    assert len(fs.list_files(data_directory + \"/sample/different_case_examples\")) == 2\n",
    "\n",
    "    # test the search_suffix option is working\n",
    "    assert len(fs.list_files(data_directory + \"/sample/polarmetric\", search_suffix='HH')) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eece7a5-5f4e-478a-9ccf-693a2699aceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_file_search_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m, in \u001b[0;36mtest_file_search_methods\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m higher_level_list_of_dats \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mlist_files(data_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# this checks that the list of files is not empty\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m higher_level_list_of_dats  \n\u001b[1;32m     10\u001b[0m lower_level_list_of_dats \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mlist_files(data_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sample/polarmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# test that all the files found in a lower level directory were also found when searching in a higher level directory\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_file_search_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa893575-d8ed-4d3a-9740-e16a51e6865c",
   "metadata": {},
   "source": [
    "## Test file selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "076ae5d4-5471-4945-b2e5-d1932d46b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use two different methods for selecting the same ApRES DAT file from a google bucket. \n",
    "#  In each case load it and then check that we have loaded the correct file. \n",
    "\n",
    "def test_file_selection_methods():\n",
    "    directory='gs://ldeo-glaciology/GL_apres_2022/A101'\n",
    "    fs1 = load.from_dats(max_range=1400)\n",
    "    fs1.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_numbers_to_process=[0,1])\n",
    "\n",
    "    fs2 = load.from_dats(max_range=1400)\n",
    "    fs2.load_all(directory, \n",
    "                remote_load = True,\n",
    "                file_names_to_process = fs1.dat_filenames_to_process)\n",
    "\n",
    "    assert fs1.data.identical(fs2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced97345-a02e-4bbb-a428-1bcb9eb74d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_selection_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d8dc1-9f2f-4ecd-8aa0-7a92586cf847",
   "metadata": {},
   "source": [
    "## Test polarmetric loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf06f517-d30a-4886-833e-aeec40104a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test polarmetric local loading by loading the same waypoint twice as if it is two different ones and chaeking \n",
    "# that you get the same thing twice.\n",
    "\n",
    "# tests the attended option and the polarmetric option from locally stored dat files (as opposed to cloud stored dat files)\n",
    "\n",
    "def test_polarmetric_load():\n",
    "    \n",
    "    fs = load.from_dats()\n",
    "    fs.load_all(attended=True, \n",
    "                directory=[\"data/sample/polarmetric\", \"data/sample/polarmetric\"], \n",
    "                polarmetric=True)\n",
    "    \n",
    "    assert len(fs.data.waypoint) == 2\n",
    "    assert all(fs.data.isel(waypoint=0).filename.values == fs.data.isel(waypoint=1).filename.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed8a5486-c837-4ab4-ac41-20af366571e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polarmetric_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e835d-ae9d-47a9-b9fc-f8ee196d1be8",
   "metadata": {},
   "source": [
    "## Test `generate_xarray` and `load_zarr` wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00fd03b0-b277-4df1-99b3-21c6047ee6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test `generate_xarray` and `load_zarr` wrappers\n",
    "def test_wrappers():\n",
    "    \n",
    "    from_DAT_unattended = load.generate_xarray(directory='data/sample/single_dat_file/', \n",
    "                file_numbers_to_process = [0], \n",
    "                bursts_to_process=[0],\n",
    "                )\n",
    "\n",
    "    from_zarr = load.load_zarr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "066b4011-15d0-4945-b40c-2cf79f943f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wrappers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a390ba7-5893-4fd7-9414-d1107f2acd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the displacement calculation\n",
    "\n",
    "def test_displacement_calculation():\n",
    "    from_zarr = load.load_zarr()  # lazily load a large APRES dataset from Greenland\n",
    "    p1 = from_zarr.isel(time=2000).profile_stacked # select a profile \n",
    "    p2 = from_zarr.isel(time=2100).profile_stacked # select a different profile \n",
    "       \n",
    "    utils.compute_displacement(p1, p2)    # calculate the displacement between the two profiles\n",
    "\n",
    "    t = from_zarr.sel(time='2022-07-17').profile_stacked   # select all the profiles on a specfic date\n",
    "    results = t.displacement_timeseries(bin_size = 30, offset = 3) # compute a time series of displacement from these data. Use non-default values for offset and bin_size \n",
    "\n",
    "    assert (abs(results)>0).all().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44e3e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test_displacement_calculation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e3e4fdd3e8b5cf0803f6688fb4cf910bea2d93a4911237a73f72af70e10228"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
